{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T07:25:51.703445Z",
     "start_time": "2024-09-04T07:25:51.670673Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "from helper import *\n",
    "from coval.coval.conll.reader import get_coref_infos\n",
    "from coval.coval.eval.evaluator import evaluate_documents as evaluate\n",
    "from coval.coval.eval.evaluator import muc, b_cubed, ceafe, lea\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mstats\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhelper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcoval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcoval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconll\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mreader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_coref_infos\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcoval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcoval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluate_documents \u001B[38;5;28;01mas\u001B[39;00m evaluate\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'helper'"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read(key, response):\n",
    "    '''read keyfile \n",
    "        key:  the keyfile path for gold_map\n",
    "        response: the keyfile path for model_map  \n",
    "    '''\n",
    "    return get_coref_infos('%s' % key, '%s' % response,\n",
    "            False, False, True)\n",
    "\n",
    "def give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path):\n",
    "    '''get MUC, B-cubed, CEAFe, LEA, CoNLL F1 evaluation\n",
    "        gold_map_path: the path for gold_map\n",
    "        model_map_path: the path for model_map\n",
    "        keyfile_save_path: the path to save the keyfiles generated by the func 'read'\n",
    "    '''\n",
    "    gold_map=pd.read_pickle(gold_map_path)\n",
    "    model_map=pd.read_pickle(model_map_path)\n",
    "    save_folder=os.path.join(keyfile_save_path)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "        print(f\"Folder '{keyfile_save_path}' created successfully\")  \n",
    "    else:\n",
    "        print('Testing') \n",
    "    gold_map_conll_file=save_folder + f'/evt_gold_test.keyfile'\n",
    "    model_map_conll_file=save_folder + f'/evt_model_test.keyfile'\n",
    "    generate_key_file(gold_map.items(), 'evt', save_folder, gold_map_conll_file)\n",
    "    generate_key_file(model_map.items(), 'evt', save_folder, model_map_conll_file)\n",
    "    doc= read(gold_map_conll_file, model_map_conll_file)\n",
    "    mr, mp, mf = np.round(np.round(evaluate(doc, muc), 3) * 100, 1)\n",
    "    br, bp, bf = np.round(np.round(evaluate(doc, b_cubed), 3) * 100, 1)\n",
    "    cr, cp, cf = np.round(np.round(evaluate(doc, ceafe), 3) * 100, 1)\n",
    "    lr, lp, lf = np.round(np.round(evaluate(doc, lea), 3) * 100, 1)\n",
    "    conf = np.round((mf + bf + cf) / 3, 1)\n",
    "    muc_res = f\"MUC: R {mr} P {mp} F1 {mf}\\n\"\n",
    "    bcubed_res = f\"B-cubed: R {br} P {bp} F1 {bf}\\n\"\n",
    "    ceafe_res = f\"CEAFe: R {cr} P {cp} F1 {cf}\\n\"\n",
    "    lea_res = f\"LEA: R {lr} P {lp} F1 {lf}\\n\"\n",
    "    conll_res = f\"CoNLL F1: {conf}\\n\"\n",
    "    multi_metrics_str = muc_res + bcubed_res + ceafe_res + lea_res + conll_res\n",
    "    print(multi_metrics_str)\n",
    "    with open(os.path.join(save_folder,'multi_metrics.txt'), \"w\") as file:\n",
    "        file.write(multi_metrics_str)\n",
    "    multi_metrics_dict = {'MUC':{'R':mr, 'P':mp, 'F1': mf},\n",
    "                    'B-cubed':{'R':br, 'P':bp, 'F1': bf},\n",
    "                    'CEAFe':{'R':cr, 'P':cp, 'F1': cf},\n",
    "                    'LEA':{'R',lr, 'P',lp,'F1',lf},\n",
    "                    'CoNLL F1':{conf}}\n",
    "    return multi_metrics_dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def give_evaluation_result_2(gold_map_path,model_map_path,save_path):\n",
    "    gold_map=pd.read_pickle(gold_map_path)\n",
    "    model_map=pd.read_pickle(model_map_path)\n",
    "    save_folder=save_path\n",
    "    # if not os.path.exists(save_folder):\n",
    "    #     os.makedirs(save_folder)\n",
    "    #     print(f\"Folder '{model_tag}' created successfully\")  \n",
    "    # else:\n",
    "    print('Testing') \n",
    "    gold_map_conll_file=save_folder + f'/evt_gold_test.keyfile'\n",
    "    model_map_conll_file=save_folder + f'/evt_model_test.keyfile'\n",
    "    generate_key_file(gold_map.items(), 'evt', save_folder, gold_map_conll_file)\n",
    "    generate_key_file(model_map.items(), 'evt', save_folder, model_map_conll_file)\n",
    "    doc= read(gold_map_conll_file, model_map_conll_file)\n",
    "    mr, mp, mf = np.round(np.round(evaluate(doc, muc), 3) * 100, 1)\n",
    "    br, bp, bf = np.round(np.round(evaluate(doc, b_cubed), 3) * 100, 1)\n",
    "    cr, cp, cf = np.round(np.round(evaluate(doc, ceafe), 3) * 100, 1)\n",
    "    lr, lp, lf = np.round(np.round(evaluate(doc, lea), 3) * 100, 1)\n",
    "    conf = np.round((mf + bf + cf) / 3, 1)\n",
    "    mu=(mr,mp,mf)\n",
    "    b_cu=(br,bp,bf)\n",
    "    cea=(cr,cp,cf)\n",
    "    le=(lr,lp,lf)\n",
    "    return mu, b_cu,cea,le,conf\n",
    "\n",
    "\n",
    "def B_cubed_pairwise_t_test(test_programme_path):\n",
    "    base_path=os.path.join(test_programme_path,'base')\n",
    "    aug_path=os.path.join(test_programme_path,'aug')\n",
    "    base_b_cubed_list=[]\n",
    "    aug_b_cubed_list=[]\n",
    "    for t in range(10):\n",
    "        base_turn_path=os.path.join(base_path,'turn_{}'.format(t))\n",
    "        aug_turn_path=os.path.join(aug_path,'turn_{}'.format(t))\n",
    "        base_mu,base_b_cu,base_cea,base_le,base_conf=give_evaluation_result_2(base_turn_path+r'/gold_map',base_turn_path+r'/model_map',base_turn_path) \n",
    "        aug_mu,aug_b_cu,aug_cea,aug_le,aug_conf=give_evaluation_result_2(aug_turn_path+r'/gold_map',aug_turn_path+r'/model_map',aug_turn_path) \n",
    "        base_b_cubed_list.append(base_b_cu[-1])\n",
    "        aug_b_cubed_list.append(aug_b_cu[-1])\n",
    "    print(stats.ttest_rel(base_b_cubed_list, aug_b_cubed_list))\n",
    "# ttest for ecb+\n",
    "stats.ttest_rel([84.1, 85.6, 83.5, 84.4, 84.3, 84.5,82.8], [85.5, 86, 85.1, 84.9, 84.8, 84.9, 84.3])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Main Exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ECB+"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'ecb'\n",
    "ECRsystem = 'baseline'\n",
    "save_path_prefix =  f'/home/yaolong/Rationale4CDECR-main/outputs/{exp_type}/{dataset}/{ECRsystem}/dual/dual_save_data/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'ecb'\n",
    "ECRsystem = 'enhanced'\n",
    "save_path_prefix =  f'/home/yaolong/Rationale4CDECR-main/outputs/{exp_type}/{dataset}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 FCC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'fcc'\n",
    "ECRsystem = 'baseline'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{dataset}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'fcc'\n",
    "ECRsystem = 'enhanced'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{dataset}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 GVC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'gvc'\n",
    "ECRsystem = 'baseline'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{dataset}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'main'\n",
    "dataset = 'gvc'\n",
    "ECRsystem = 'enhanced'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{dataset}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 CAD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ablation_study'\n",
    "data_type = 'CAD'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TIA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ablation_study'\n",
    "data_type = 'TIA'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 CIA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ablation_study'\n",
    "data_type = 'CIA'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 TAD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ablation_study'\n",
    "data_type = 'TAD'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 RMCT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ablation_study'\n",
    "data_type = 'RMCT'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Out-Of-the-Domain Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 ECB_Cross_FCC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ood_test'\n",
    "data_type = 'ecb_cross_fcc'\n",
    "ECRsystem = 'baseline'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ood_test'\n",
    "data_type = 'ecb_cross_fcc'\n",
    "ECRsystem = 'enhanced'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 FCC_Cross_ECB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ood_test'\n",
    "data_type = 'fcc_cross_ecb'\n",
    "ECRsystem = 'baseline'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_type = 'ood_test'\n",
    "data_type = 'fcc_cross_ecb'\n",
    "ECRsystem = 'enhanced'\n",
    "save_path_prefix =  f'../outputs/{exp_type}/{data_type}/{ECRsystem}/eval_results'\n",
    "gold_map_path = os.path.join(save_path_prefix ,'gold_map') \n",
    "model_map_path = os.path.join(save_path_prefix ,'model_map') \n",
    "keyfile_save_path = os.path.join(save_path_prefix ,'multi_metrics')\n",
    "ecb_main_enhanced = give_evaluation_result(gold_map_path, model_map_path, keyfile_save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ttest for ecb+\n",
    "stats.ttest_rel([84.1, 85.6, 83.5, 84.4, 84.3, 84.5,82.8], [85.5, 86, 85.1, 84.9, 84.8, 84.9, 84.3])"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
